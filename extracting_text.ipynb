{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "### I wanted to use Apache Spark for this task to make the processing very scalable and using all CPU cores of my machine for parallel processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<SparkContext master=local[11] appName=knotebook>",
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[11]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>knotebook</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext(\"local[11]\", \"knotebook\")\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import * "
   ]
  },
  {
   "source": [
    "### This loads all job postings in an Spark Dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The job postings where downloaded to *data/html_job_postings/html_job_postings*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = sc.wholeTextFiles(\"data/html_job_postings/html_job_postings/*\")\n",
    "sdf = text_files.repartition(10).toDF().withColumnRenamed(\"_1\", \"filename\").withColumnRenamed(\"_2\", \"content\")"
   ]
  },
  {
   "source": [
    "### An user defined function is applied on the data frame to use beautiful soup to extract information from the HTML content"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTitleBodyBullets(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    bullets = [elem.text.strip() for elem in soup.select('li')]\n",
    "    return (str(soup.title.string), str(soup.body.getText()), bullets)\n",
    "\n",
    "extractTitleBodyBullets_udf = udf(\n",
    "    extractTitleBodyBullets,\n",
    "    StructType([\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"body\", StringType(), False),\n",
    "    StructField(\"bullets\", ArrayType(StringType()), False)\n",
    "])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_new = sdf.select(\"*\", extractTitleBodyBullets_udf(sdf['content'])).select('extractTitleBodyBullets(content).*')"
   ]
  },
  {
   "source": [
    "### Now the Spark Dataframe is easily converted to Pandas for further processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sdf_new.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1336"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "source": [
    "### Remove the duplicates and check the impact"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"body\", \n",
    "                     keep = False, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1320"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "source": [
    "### Filter the jobs to only include data science jobs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['title'].str.lower().str.contains(\"data scient\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "403"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                title  \\\n1             V.I.E. - Data Scientist - Charlotte, NC   \n2          (Entry-Level) Data Scientist - Chicago, IL   \n8                       Data Scientist - Issaquah, WA   \n12        IT Data Scientist - Contract - Riverton, UT   \n14                         Data Scientist - Plano, TX   \n...                                               ...   \n1316     Insurance Data Scientist - Chicago, IL 60661   \n1317  Senior Data Scientist - San Francisco, CA 94110   \n1326        Senior Data Scientist - San Francisco, CA   \n1330         Data Scientist - San Francisco, CA 94103   \n1332                  Data Scientist - Glen Mills, PA   \n\n                                                   body  \\\n1     V.I.E. - Data Scientist - Charlotte, NC\\nAmeri...   \n2     (Entry-Level) Data Scientist - Chicago, IL\\nDa...   \n8     Data Scientist - Issaquah, WA\\nJob Details\\nLe...   \n12    IT Data Scientist - Contract - Riverton, UT\\nP...   \n14    Data Scientist - Plano, TX\\nOverview\\nPosition...   \n...                                                 ...   \n1316  Insurance Data Scientist - Chicago, IL 60661\\n...   \n1317  Senior Data Scientist - San Francisco, CA 9411...   \n1326  Senior Data Scientist - San Francisco, CA\\nJob...   \n1330  Data Scientist - San Francisco, CA 94103\\nWant...   \n1332  Data Scientist - Glen Mills, PA\\nSSRS Data Sci...   \n\n                                                bullets  \n1     [To improve our methods and tools for Machine ...  \n2     [\\nBe the go-to person for Data ingest and sto...  \n8     [Serve as a subject matter expert in Data Scie...  \n12    [Master’s degree, PhD degree preferred, 12+ ye...  \n14    [Excellent visual, written and verbal communic...  \n...                                                 ...  \n1316  [You come in with 1-2 years of professional st...  \n1317  [Build more affordable products, Bring them to...  \n1326  [Perform hands-on analysis of large volumes of...  \n1330  [\\nApply statistics techniques to improve Wish...  \n1332  [Use machine learning methods (e.g., cluster a...  \n\n[403 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>body</th>\n      <th>bullets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>V.I.E. - Data Scientist - Charlotte, NC</td>\n      <td>V.I.E. - Data Scientist - Charlotte, NC\\nAmeri...</td>\n      <td>[To improve our methods and tools for Machine ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(Entry-Level) Data Scientist - Chicago, IL</td>\n      <td>(Entry-Level) Data Scientist - Chicago, IL\\nDa...</td>\n      <td>[\\nBe the go-to person for Data ingest and sto...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Data Scientist - Issaquah, WA</td>\n      <td>Data Scientist - Issaquah, WA\\nJob Details\\nLe...</td>\n      <td>[Serve as a subject matter expert in Data Scie...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>IT Data Scientist - Contract - Riverton, UT</td>\n      <td>IT Data Scientist - Contract - Riverton, UT\\nP...</td>\n      <td>[Master’s degree, PhD degree preferred, 12+ ye...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Data Scientist - Plano, TX</td>\n      <td>Data Scientist - Plano, TX\\nOverview\\nPosition...</td>\n      <td>[Excellent visual, written and verbal communic...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1316</th>\n      <td>Insurance Data Scientist - Chicago, IL 60661</td>\n      <td>Insurance Data Scientist - Chicago, IL 60661\\n...</td>\n      <td>[You come in with 1-2 years of professional st...</td>\n    </tr>\n    <tr>\n      <th>1317</th>\n      <td>Senior Data Scientist - San Francisco, CA 94110</td>\n      <td>Senior Data Scientist - San Francisco, CA 9411...</td>\n      <td>[Build more affordable products, Bring them to...</td>\n    </tr>\n    <tr>\n      <th>1326</th>\n      <td>Senior Data Scientist - San Francisco, CA</td>\n      <td>Senior Data Scientist - San Francisco, CA\\nJob...</td>\n      <td>[Perform hands-on analysis of large volumes of...</td>\n    </tr>\n    <tr>\n      <th>1330</th>\n      <td>Data Scientist - San Francisco, CA 94103</td>\n      <td>Data Scientist - San Francisco, CA 94103\\nWant...</td>\n      <td>[\\nApply statistics techniques to improve Wish...</td>\n    </tr>\n    <tr>\n      <th>1332</th>\n      <td>Data Scientist - Glen Mills, PA</td>\n      <td>Data Scientist - Glen Mills, PA\\nSSRS Data Sci...</td>\n      <td>[Use machine learning methods (e.g., cluster a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>403 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "### Save the DataFrame to disk so we can load it at a later time for future parts of the project."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"datascience_jobs.pkl\") "
   ]
  },
  {
   "source": [
    "it can later be retrieved via * pd.read_pickle(\"datascience_jobs.pkl\") * "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitksparkconda1aacc4d7dac045b0b64c258692eebc71",
   "display_name": "Python 3.7.6 64-bit ('kspark': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}